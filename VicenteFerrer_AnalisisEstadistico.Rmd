---
title: 'Estadística Avanzada: A2 - Analítica descriptiva e inferencial'
author: "Autor: Raúl Vicente Ferrer"
date: "Noviembre 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
Sys.setenv(LANG = "en")
Sys.setlocale("LC_ALL", "en_US.UTF-8")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# https://cran.r-project.org/web/packages/ggplot2/index.html
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('knitr')) install.packages('knitr'); library('knitr')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('kableExtra')) install.packages('kableExtra'); library('kableExtra')
# https://cran.r-project.org/web/packages/nortest/index.html
if (!require('nortest')) install.packages('nortest'); library('nortest')
```

******
# Lectura del fichero y preparación de los datos
******

```{r message= FALSE, warning=FALSE}
claim <- read.csv("./train_clean2.csv", header=TRUE) 
```

```{r message= FALSE, warning=FALSE}
str(claim)
summary(claim)
```

******
# Coste de los siniestros  
******

## Análisis visual

* Diagrama de caja de la distribución de la variable 'UltCost':

```{r}
boxplot(claim$UltCost, main="UltCost")
```

* Transformación a escala logarítmica de la variable 'UltCost' y diagrama de caja:

```{r}
logUltCost <- log(claim$UltCost)
boxplot(logUltCost, main="Log UltCost")
```

* Interpretación de los gráficos:
El primer gráfico presenta una fuerte asimetría a la izquierda.
Trás aplicar la transformación logarítmica, podemos ver que los valores se distribuyen entre 2 y 13.


## Comprobación de normalidad

* Inspección visual de la normalidad de la variable 'UltCost':

Un gráfico Q-Q normal nos muestra como se aproximan estos datos a una distribución normal:

```{r}
qqnorm(claim$UltCost, main = "", xlab = "Cuantiles teóricos", ylab = "Cuantiles muestrales")
qqline(claim$UltCost)
```

Se observa que no siguen una distribución normal.
Esto es más fácil de visualizar con un histograma de densidad y una curva de distribución normal superpuesta:

```{r}
hist(claim$UltCost, probability = TRUE, main = "UltCost", xlab = "Población", ylab = "Densidad",  breaks=20)
x   <- seq(min(claim$UltCost), max(claim$UltCost), length = 1000)
y <- dnorm(x, mean(claim$UltCost), sd(claim$UltCost))
lines(x, y, col = "blue")
```

* Contraste de normalidad de Lilliefors:

```{r}
lillie.test(claim$UltCost)
```

Como p-value es menor de 0.05 se rechaza la hipótesis de normalidad.

* Inspección visual y contraste de la normalidad de la variable 'UltCost' en escala logarítmica:

Un gráfico Q-Q normal nos muestra como se aproximan estos datos a una distribución normal:

```{r}
qqnorm(logUltCost, main = "", xlab = "Cuantiles teóricos", ylab = "Cuantiles muestrales")
qqline(logUltCost)
```

Se observa que siguen una distribución normal.
Esto es más fácil de visualizar con un histograma de densidad y una curva de distribución normal superpuesta:

```{r}
hist(logUltCost, probability = TRUE, main = "LogUltCost", xlab = "Población", ylab = "Densidad",  breaks=20)
x   <- seq(min(logUltCost), max(logUltCost), length = 1000)
y <- dnorm(x, mean(logUltCost), sd(logUltCost))
lines(x, y, col = "red")
```

Contraste de normalidad de Lilliefors:

```{r}
lillie.test(logUltCost)
```

Como p-value es mayor de 0.05 se acepta la hipótesis de normalidad.

## Intervalo de confianza de la media poblaciona de la variable 'UltCost'

* Cálculo manual del intervalo de confianza al 95% de la media poblacional de la variable 'UltCost':

Media:
```{r}
print(mean(claim$UltCost))
```

Intervalo de confianza:
```{r}
n <- nrow(claim)
alpha <- (1-0.95)
SE <- sd(claim$UltCost) / sqrt(n)
t <- qnorm(alpha/2, lower.tail=FALSE)
L <- mean(claim$UltCost) - t*SE
U <- mean(claim$UltCost) + t*SE
c(L,U)
```

* ¿Podemos asumir la hipótesis de normalidad para el cálculo del intervalo de confianza sobre la media muestral del coste en escala original?

El Teorema del Límite Central (TLC) establece que el contraste de hipótesis sobre la media de una muestra se aproxima a una distribución normal aunque la población original no siga una distribución normal, siempre que el tamaño de la muestra sea suficientemente grande, es decir, mayor de 30. Así que, en este caso, se cumple el TLC y por o tanto podemos asumir la hipótesis de normalidad para el cálculo del intervalo de confianza sobre la media muestral.

* Interpretación del intervalo de confianza:

Si obtenemos infinitas muestras del conjunto de datos, el 95% de los intervalos de confianza calculados a partir de esas muestras contendrían el valor medio del coste.

******
# Coste inicial y final de los siniestros  
******

## Justificación del test a aplicar

Por el teorema del límite central, podemos asumir normalidad y se desea realizar un test sobre la media.

Como no se conoce la varianza de la población aplicamos la distribución t, 

Comprobamos igualdad de varianzas:

```{r}
var.test( claim$IniCost, claim$UltCost )
```

p<0.001, por lo que descartamos igualdad de varianzas.

Se trata de un contraste de dos muestras emparejadas sobre la media con varianzas desconocidas y bilateral.Ya que queremos comparar dos muestras que están univocamente relacionadas.

## Hipótesis nula y alternativa

$H_0: µ_d = 0$

$H_1: µ_d \neq 0$

## Cálculos

```{r}
testhipotesis <- function (m1, m2, NConf=0.95, paired=TRUE, var.equal=TRUE, alternative="two.sided") {
  alpha <- (1-NConf)
  mean1 <- mean(m1)
  n1 <- length(m1)
  sd1 <- sd(m1)
  mean2 <- mean(m2)
  n2 <- length(m2)
  sd2 <- sd(m2)
  diff <- m1-m2
  nD <- length(diff)
  meanD <- mean(diff)
  sD <- sd(diff)
  #paired==FALSE
  if (paired==FALSE){
    #var.equal==TRUE
    if (var.equal==TRUE){
      s <- sqrt(((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2))
      Sb <- s*sqrt(1/n1 + 1/n2)
      df <- n1+n2-2
    }
    #var.equal==FALSE
    else{
      Sb <- sqrt(sd1^2/n1 + sd2^2/n2)
      df <- ((sd1^2/n1 + sd2^2/n2)^2)/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
    }
    t <- abs((mean1-mean2)/Sb)
    #alternative=="two.sided"
    if (alternative=="two.sided"){
      tcritical <- qt(alpha/2, df, lower.tail=FALSE)
      pvalue <- pt(abs(t), df, lower.tail=FALSE )*2
    }
    #alternative=="menor"
    else if (alternative=="menor"){
      tcritical <- qt(alpha, df, lower.tail=TRUE)
      pvalue <- pt(t, df, lower.tail=TRUE)
    }
    #alternative=="mayor"
    else{
      tcritical <- qt(alpha, df, lower.tail=FALSE)
      pvalue <- pt(t, df, lower.tail=FALSE)
    }
    result <- data.frame(t, tcritical, pvalue)
    result %>% kable() %>% kable_styling()
  }
  #paired==TRUE
  else{
    t <- abs(meanD/(sD/sqrt(nD)))
    #alternative=="two.sided"
    if (alternative=="two.sided"){
      tcritical <- qt(alpha/2, df=nD-1, lower.tail=FALSE)
      pvalue <- pt(abs(t), df=nD-1, lower.tail=FALSE)*2
    }
    #alternative=="menor"
    else if (alternative=="menor"){
      tcritical <- qt(alpha, df=nD-1, lower.tail=TRUE)
      pvalue <- pt(abs(t), df=nD-1, lower.tail=TRUE)
    }
    #alternative=="mayor"
    else{
      tcritical <- qt(alpha, df=nD-1, lower.tail=FALSE)
      pvalue <- pt(abs(t), df=nD-1, lower.tail=FALSE)
    }
    result <- data.frame(t, tcritical, pvalue)
    result %>% kable() %>% kable_styling()
  
  }
  return(result)
}

result3<-testhipotesis(claim$UltCost, claim$IniCost, paired=TRUE, var.equal=FALSE, alternative = "two.sided")
result3
```

## Conclusión

El valor crítico para un nivel de confianza del 95% es 1.960011	 y el valor observado es 20.80108. Por lo tanto, nos encontramos en la zona de rechazo de la hipótesis nula y podemos concluir que hay diferencias entre IniCost y UltCost. Se concluye lo mismo con el valor p, que da un valor de 1.067535 × 10^−95^, muy inferior a alpha=0.05.

## Comprobación

```{r}
t.test(claim$UltCost, claim$IniCost, var.equal=FALSE, paired=TRUE, alternative = "two.sided")
```

Los valores coinciden.

******
# Diferencia de salario según género  
******

## Análisis visual

```{r}
Mujeres <- claim[claim$Gender=="F",]
Hombres <- claim[claim$Gender=="M",]

boxplot(log(Mujeres$WeeklyWages), log(Hombres$WeeklyWages), names=c("Mujeres","Hombres"), main="Sueldo" )
```

## Interpretación

Se observan pequeñas diferencias entre sueldos, el límite inferior de los sueldos es menor en mujeres, pero el superior parece ser superior. Es necesario recurrir a un contraste de hipótesis para confirmar si estas diferencias observadas son significativas.

## Hipótesis nula y alternativa

$H_0: H = M$

$H_1: H > M $

## Justificación del test a aplicar

Por el teorema del límite central, podemos asumir normalidad y se desea realizar un test sobre la media.

Como no se conoce la varianza de la población aplicamos la distribución t, 

Comprobamos igualdad de varianzas:

```{r}
var.test(Hombres$WeeklyWages, Mujeres$WeeklyWages)
```

p<0.001, por lo que descartamos igualdad de varianzas.

Se trata de un contraste de dos muestras independientes sobre la media con varianzas desconocidas y unilateral por la derecha.

## Cálculos

```{r warning=FALSE}
result4<-testhipotesis(Hombres$WeeklyWages, Mujeres$WeeklyWages, paired=FALSE, var.equal=FALSE, alternative = "greater")
result4
```

Finalmente, se asignan los nuevos códigos:

## Conclusión

El valor crítico para un nivel de confianza del 95% es 1.644922	 y el valor observado es 28.8127. Por lo tanto, nos encontramos en la zona de rechazo de la hipótesis nula y podemos concluir que hay diferencias entre los salarios de hombres y mujeres. Se concluye lo mismo con el valor p, que da un valor de 1.437086 × 10^−179^, muy inferior a alpha=0.05. Así que estamos en la zona a favor de la hipótesis alternativa y podemos aceptar que los hombres cobran más que las mujeres en promedio a la semana. 

## Comprobación

```{r}
t.test(Hombres$WeeklyWages, Mujeres$WeeklyWages, var.equal=FALSE, paired=FALSE, alternative = "greater")
```

Se obtiene el mismo resultado.

******
# Salario semanal (II)  
******

## Hipótesis nula y alternativa

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Justificación del test a aplicar

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Cálculos

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Conclusión

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Comprobación

```{r}

```

Finalmente, se asignan los nuevos códigos:

******
# Diferencia de jornada según género 
******

## Análisis visual

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Interpretación

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Hipótesis y alternativa

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Tipo de test

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Cálculos

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Conclusión

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Comprobación

```{r}

```

******
# Salario por hora 
******

## Hipótesis nula y alternativa

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Tipo de test

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Cálculos

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Conclusión

```{r}

```

Finalmente, se asignan los nuevos códigos:

## Comprobación

```{r}

```

Finalmente, se asignan los nuevos códigos:

******
# Resumen ejecutivo 
******

finalmente, se asignan los nuevos códigos:

******
# Bibliografía
******

* Apuntes y recursos de la asignatura.